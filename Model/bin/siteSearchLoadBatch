#!/usr/bin/python3

import argparse
import json
import os
import sys
import traceback
import requests

# Configuration
BATCH_ID_FIELD = 'batch-id'
UNIQUE_KEY_FIELD = 'id'

# Authentication
USER = os.environ['SOLR_USER'] if ('SOLR_USER' in os.environ) else ''
PASS = os.environ['SOLR_PASSWORD'] if ('SOLR_PASSWORD' in os.environ) else ''
AUTH = (USER, PASS)

# Parse the arguments
def parse_args():
    help = """
Add, update, or remove batches or individual files from Solr's index.

Commits on success.  Rolls back on failure.

Examples:
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search index --batch-dir DIR_PATH
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search index --file FILE_1 FILE_2
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search delete --batch-type-name BATCH_TYPE BATCH_NAME
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search delete --batch-id BATCH_ID_1 BATCH_ID_2
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search delete --doc-key UNIQUE_KEY_1 UNIQUE_KEY_2
"""

    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=help)

    parser.add_argument('solr_url', help='The URL of the Solr instance, including core, but not including operation (ex: http://localhost:8080/solr/site_search).')

    subparsers = parser.add_subparsers(title='subcommands', help='Add a subcommand name followed by -h for specific help on it.')

    # Index subparser
    parser_index = subparsers.add_parser('index', help='Index files or batches into Solr.')
    parser_index.set_defaults(func=index)
    parser_index.add_argument('--batch-dir', help='Index a batch contained in the given directory. The directory should contain a batch.json file and the .json files containing the data. The JSON files should adhere to the requirements listed in the --file option. The data files will be loaded first, and batch.json last, indicating a successful load.')
    parser_index.add_argument('--validate-only', action='store_true', help='Validate the batch provided with --batch-dir, but do not index it.')
    parser_index.add_argument('--file', nargs='+', metavar='FILE', dest='file_paths', help='Index individual files. Each file must be a JSON-formatted list of Solr documents, that is, a JSON array containing JSON objects.')

    # Delete subparser
    parser_delete = subparsers.add_parser('delete', help='Delete documents or batches from Solr.')
    parser_delete.set_defaults(func=delete)
    parser_delete.add_argument('--batch-type-name', nargs=2, metavar=('BATCH_TYPE', 'BATCH_NAME'), help='Delete a batch of documents with the given batch type and batch name. Provide the batch type followed by the batch name, separated by a space (ex: --batch-type-name organism pberANKA).')
    parser_delete.add_argument('--batch-id', nargs='+', metavar='BATCH_ID', dest='batch_ids', help='Delete a batch of documents by batch ID.')
    parser_delete.add_argument('--doc-key', nargs='+', metavar='UNIQUE_KEY', dest='doc_keys', help='Delete documents by unique key.')

    # Rollback subparser
    parser_rollback = subparsers.add_parser('rollback', help='Rollback any staged changes in Solr.')
    parser_rollback.set_defaults(func=rollback)

    args = parser.parse_args()

    # Validate arguments
    if 'func' not in args:
        parser.print_usage()
        sys.exit(2)

    if args.func == index:
        if not (args.batch_dir or args.file_paths):
            parser.error('To index, please provide at least one of: --batch-dir, --file. Add -h for help.')
        if args.validate_only and not args.batch_dir:
            parser.error('--validate-only can only be used with --batch-dir')

    if args.func == delete and not (args.batch_type_name or args.batch_ids or args.doc_keys):
        parser.error('To delete, please provide at least one of: --batch-type-name, --batch-id, --doc-key. Add -h for help.')

    return args

# A wrapper for running commands
def run(kwargs):
    # Remove and store arguments that don't get passed to func
    func = kwargs['func']
    del kwargs['func']

    update_url = kwargs['solr_url'] + '/update'

    # If func is rollback, just do it
    if func is rollback:
        func(update_url)

    # Otherwise, execute func with safeguards
    else:
        try:
            # Run the command
            changes_staged = func(**kwargs)

            if changes_staged:
                # Commit the changes
                print('Committing changes')
                solr_request('POST', update_url, data='<commit/>', auth=AUTH, headers={'content-type':'application/xml'})
                print('Changes committed')
            else:
                print('No change')

        except Exception as e:
            print(traceback.format_exc())

            # If changes have been staged, attempt to roll them back
            if hasattr(e, 'changes_staged') and e.changes_staged:
                try:
                    rollback(update_url)
                    print('An error occurred and changes were rolled back.')

                except Exception as e:
                    print(traceback.format_exc())
                    print('An error occurred, but rollback failed. Changes could still be staged in Solr.')

            sys.exit(1)

# Index files or batches
def index(solr_url, batch_dir=None, file_paths=None, validate_only=False):
    update_url = solr_url + '/update'
    select_url = solr_url + '/select'
    changes_staged = False

    try:
        if batch_dir:
            # Validate the batch
            validate_batch(batch_dir)

            if not validate_only:
                # Read batch.json
                batch_json_path = batch_dir + '/batch.json'
                with open(batch_json_path) as batch_json_file:
                    batch_json = json.load(batch_json_file)[0]

                batch_type = batch_json['batch-type']
                batch_name = batch_json['batch-name']
                batch_id = batch_json['batch-id']

                # Check to see whether this exact batch with same version already exists in Solr
                # We do this by looking for the batch-meta document
                url = select_url + '?q=batch-id:{} AND document-type:batch-meta&rows=0'.format(batch_id)
                print('Checking for the absence of batch-meta for batch {} in Solr'.format(batch_id))
                response = solr_request('GET', url, auth=AUTH)

                if response.json()['response']['numFound']:
                    print('Skipping batch {} - already loaded in Solr'.format(batch_id))
                else:
                    # Check to see whether Solr has ANY documents belonging to this batch
                    url = select_url + '?q=batch-type:{} AND batch-name:{}&rows=0'.format(batch_type, batch_name)
                    print("Checking for the absence of any batch '{} {}' documents in Solr".format(batch_type, batch_name))
                    response = solr_request('GET', url, auth=AUTH)

                    if response.json()['response']['numFound']:
                        sys.exit("Error: Documents with batch-type '{}' and batch-name '{}' already exist in Solr, but there is no batch-meta with a version number that matches the one you want to load. Delete the existing documents before loading this batch.".format(batch_type, batch_name))
                    else:
                        # Index all data files
                        for obj in os.scandir(batch_dir):
                            if obj.is_file() and obj.name.endswith('.json') and obj.name != 'batch.json':
                                index_file(obj, update_url)
                                changes_staged = True

                        # Finally, index batch.json
                        index_file(batch_json_path, update_url)
                        changes_staged = True

        # If there are new files to index, index them
        if file_paths:
            for path in file_paths:
                index_file(path, update_url)
                changes_staged = True

    except Exception as e:
        if not hasattr(e, 'changes_staged'):
            e.changes_staged = changes_staged
        raise

    return changes_staged

# Delete documents or batches
def delete(solr_url, batch_type_name=None, batch_ids=None, doc_keys=None, production=False):
    url = solr_url + '/update'
    changes_staged = False

    try:
        if batch_type_name:
            batch_type, batch_name = batch_type_name
            query_text = 'batch-type:{} AND batch-name:{}'.format(batch_type, batch_name)
            batch_text = "'{} {}'".format(batch_type, batch_name)
            delete_batch(query_text, url, batch_text)
            changes_staged = True

        # If there is a del_batch_id, use it to delete the old batch
        if batch_ids:
            for batch_id in batch_ids:
                query_text = '{}:{}'.format(BATCH_ID_FIELD, batch_id)
                delete_batch(query_text, url, batch_id)
                changes_staged = True

        # If there is a del_key, use it to delete documents
        if doc_keys:
            for key in doc_keys:
                print('Deleting document with key ' + key)
                data = '<delete><query>{}:{}</query></delete>'.format(UNIQUE_KEY_FIELD, key)
                solr_request('POST', url, data=data, auth=AUTH, headers={'content-type':'application/xml'})
                changes_staged = True

    except Exception as e:
        if not hasattr(e, 'changes_staged'):
            e.changes_staged = changes_staged
        raise

    return changes_staged

# Roll back changes
def rollback(url):
    print('Rolling back changes')

    try:
        solr_request('POST', url, data='<rollback/>', auth=AUTH, headers={'content-type':'application/xml'})
        print('Rollback successful')

    except Exception as e:
        print('Error: Unable to roll back changes')
        raise

# Validate a batch
# This involves making sure that certain fields are identical in all documents in the batch
def validate_batch(batch_dir):
    print('Validating batch')

    # Read batch.json
    batch_json_path = batch_dir + '/batch.json'

    try:
        with open(batch_json_path) as batch_json_file:
            batch_json = json.load(batch_json_file)[0]
    except FileNotFoundError:
        print('Error: batch.json not found in ' + batch_dir)
        raise

    # Get all file objects in the directory
    dir_files = [obj for obj in os.scandir(batch_dir) if obj.is_file()]
    # Define the fields that should be identical in all files
    batch_meta_fields = ['batch-type', 'batch-name', 'batch-id', 'batch-timestamp']

    # Validate each data file
    for file_obj in dir_files:
        if file_obj.name.endswith('.json') and file_obj.name != 'batch.json':
            with open(file_obj) as f:
                docs = json.load(f)
                # The fields that didn't match, if any
                mismatched_fields = []

                # Validate each document
                for doc in docs:
                    for field in batch_meta_fields:
                        if doc[field] != batch_json[field]:
                            mismatched_fields.append(field)

                    # If any fields didn't match, error out
                    if mismatched_fields:
                        error_str = "Document '{}' in file '{}' contains batch meta fields that don't match batch.json:\n".format(doc['id'], file_obj.name)
                        str_list = []

                        for field in mismatched_fields:
                            str_list.append('  "{0}": "{1}" (data file) != "{0}": "{2}" (batch.json)'.format(field, doc[field], batch_json[field]))

                        raise ValueError(error_str + '\n'.join(str_list))

    print('Batch is valid')

# Index a file
def index_file(path_like, url):
    with open(path_like) as f:
        print('Indexing file ' + f.name)
        data = f.read()
        solr_request('POST', url, data=data, auth=AUTH, headers={'content-type':'application/json'})

# Delete a batch
def delete_batch(query_text, url, batch_text):
    changes_staged = False

    try:
        # First, delete the batch-meta document
        print('Deleting batch-meta document for batch ' + batch_text)
        data = '<delete><query>{} AND document-type:batch-meta</query></delete>'.format(query_text)
        solr_request('POST', url, data=data, auth=AUTH, headers={'content-type':'application/xml'})
        changes_staged = True

        # Then delete the data documents
        print('Deleting batch ' + batch_text)
        data = '<delete><query>{}</query></delete>'.format(query_text)
        solr_request('POST', url, data=data, auth=AUTH, headers={'content-type':'application/xml'})
        changes_staged = True

    except Exception as e:
        e.changes_staged = changes_staged
        raise

# Make a request to Solr, print its response, and raise an error if necessary
def solr_request(method, url, data=None, auth=None, headers=None):
    if data:
        data = data.encode('utf-8')

    request = requests.request(method, url, data=data, auth=auth, headers=headers)

    print('Solr response:')
    print(request.text)
    request.raise_for_status()

    return request

if __name__ == '__main__':
    kwargs = vars(parse_args())
    run(kwargs)
