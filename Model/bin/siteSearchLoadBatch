#!/usr/bin/python3

import argparse
import json
import os
import sys
import traceback
import requests

# Configuration
BATCH_ID_FIELD = 'batch-id'
UNIQUE_KEY_FIELD = 'id'

# Authentication
USER = os.environ['SOLR_USER'] if ('SOLR_USER' in os.environ) else ''
PASS = os.environ['SOLR_PASSWORD'] if ('SOLR_PASSWORD' in os.environ) else ''
AUTH = (USER, PASS)

# Parse the arguments
def parse_args():
    help = """
Add, update, or remove batches or individual files from Solr's index.

Commits on success. If any changes were staged but an error occurs, all changes are rolled back.

Examples:
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search index --batch-dir DIR_PATH
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search index --file FILE_1 FILE_2
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search delete --batch-type-name BATCH_TYPE BATCH_NAME
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search delete --batch-id BATCH_ID_1 BATCH_ID_2
  siteSearchLoadBatch https://solr.local.apidb.org:8443/solr/site_search delete --doc-key UNIQUE_KEY_1 UNIQUE_KEY_2
"""

    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=help)

    parser.add_argument('solr_url', help='The URL of the Solr instance, including core, but not including operation (ex: http://localhost:8080/solr/site_search).')

    subparsers = parser.add_subparsers(title='subcommands', help='Add a subcommand name followed by -h for specific help on it.')

    # Index subparser
    parser_index = subparsers.add_parser('index', help='Index files or batches into Solr.')
    parser_index.set_defaults(func=index)
    parser_index.add_argument('--batch-dir', help="Index a new batch contained in the given directory. The directory must contain a batch.json file and the JSON files containing the data must have a '.json' extension. The JSON files should adhere to the requirements listed in the --file option. The data files will be loaded first, and batch.json last, indicating a successful load. Batch validation is performed before loading, which involves making sure that the following fields in all data documents match the values of those fields in batch.json: batch-type, batch-name, batch-id, batch-timestamp. If validation fails, an error is thrown. If a batch-meta document with batch-id equal to the batch-id of this batch exists in Solr, we assume this batch has already been successfully loaded and skip it. If a batch-meta document with the same batch-type and batch-name but different timestamp is found, an error is thrown (add --replace to replace the batch, instead). If no matching batch-meta document is found but other documents with the same batch-type and batch-name are found, this constitutes a data integrity problem and we throw an error.")
    parser_index.add_argument('--replace', action='store_true', help='Use in combination with --batch-dir to replace a batch that already exists in Solr. If the batch is not found in Solr, an error is thrown.')
    parser_index.add_argument('--validate-only', action='store_true', help='Validate the batch provided with --batch-dir, but do not index it.')
    parser_index.add_argument('--file', nargs='+', metavar='FILE', dest='file_paths', help='Index individual files. Each file must be a JSON-formatted list of Solr documents, that is, a JSON array containing JSON objects.')

    # Delete subparser
    parser_delete = subparsers.add_parser('delete', help='Delete documents or batches from Solr. Note that the script does not check to see that any documents matching the deletion query actually exist.')
    parser_delete.set_defaults(func=delete)
    parser_delete.add_argument('--batch-type-name', nargs=2, metavar=('BATCH_TYPE', 'BATCH_NAME'), help='Delete a batch of documents with the given batch type and batch name. Provide the batch type followed by the batch name, separated by a space (ex: --batch-type-name organism pberANKA).')
    parser_delete.add_argument('--batch-id', nargs='+', metavar='BATCH_ID', dest='batch_ids', help='Delete a batch of documents by batch ID.')
    parser_delete.add_argument('--doc-key', nargs='+', metavar='UNIQUE_KEY', dest='doc_keys', help='Delete documents by unique key.')

    # Rollback subparser
    parser_rollback = subparsers.add_parser('rollback', help='Rollback any staged changes in Solr.')
    parser_rollback.set_defaults(func=rollback)

    args = parser.parse_args()

    # Validate arguments
    if 'func' not in args:
        parser.print_usage()
        sys.exit(2)

    if args.func == index:
        if not (args.batch_dir or args.file_paths):
            parser.error('To index, please provide at least one of: --batch-dir, --file. Add -h for help.')
        if args.replace and not args.batch_dir:
            parser.error('--replace can only be used with --batch-dir')
        if args.validate_only and not args.batch_dir:
            parser.error('--validate-only can only be used with --batch-dir')

    if args.func == delete and not (args.batch_type_name or args.batch_ids or args.doc_keys):
        parser.error('To delete, please provide at least one of: --batch-type-name, --batch-id, --doc-key. Add -h for help.')

    return args

def run(func, solr_url, **kwargs):
    """
    A wrapper for running commands.

    Args:
        func (function): The function to run. One of index, delete, or
            rollback.
        solr_url (str): The URL to the Solr core to update.
        kwargs: Arguments to pass to func.
    """
    # If func is rollback, just do it
    if func is rollback:
        func(solr_url)

    # Otherwise, execute func with safeguards
    else:
        try:
            # Run the command
            changes_staged = func(solr_url, **kwargs)

            if changes_staged:
                # Commit the changes
                print('Committing changes')
                solr_request('POST', solr_url + '/update', data='<commit/>', auth=AUTH, headers={'content-type':'application/xml'})
                print('Changes committed')
            else:
                print('No change')

        except Exception as e:
            print(traceback.format_exc(), file=sys.stderr)

            # If changes have been staged, attempt to roll them back
            if hasattr(e, 'changes_staged') and e.changes_staged:
                try:
                    rollback(solr_url)
                    print('An error occurred and changes were rolled back.', file=sys.stderr)

                except Exception as e:
                    print(traceback.format_exc())
                    print('An error occurred, but rollback failed. Changes could still be staged in Solr.', file=sys.stderr)

            sys.exit(1)

def index(solr_url, batch_dir=None, file_paths=None, replace=False, validate_only=False):
    """Index files or batches.

    Args:
        solr_url (str): The URL to the Solr core to update.
        batch_dir (str): Index a new batch located in this directory.
        file_paths (list[path-like]): Index the files located at these
            paths.
        replace (bool): Replace the version of the batch in Solr with
            the version provided in batch_dir.
        validate_only (bool): Only validate the batch provided in
            batch_dir - do not index it.

    Returns:
        bool: True if any changes were staged in Solr.
    """
    select_url = solr_url + '/select'
    changes_staged = False

    try:
        if batch_dir:
            # Validate the batch
            validate_batch(batch_dir)

            if not validate_only:
                # Read batch.json
                batch_json_path = batch_dir + '/batch.json'
                with open(batch_json_path) as batch_json_file:
                    batch_json = json.load(batch_json_file)[0]

                batch_type = batch_json['batch-type']
                batch_name = batch_json['batch-name']
                batch_timestamp = batch_json['batch-timestamp']
                batch_id = batch_json['batch-id']

                # Search for a batch-meta doc with same batch type and name
                url = select_url + '?q=batch-type:{} AND batch-name:{} AND document-type:batch-meta'.format(batch_type, batch_name)
                print('Checking for matching batch-meta in Solr')
                response_json = solr_request('GET', url, auth=AUTH).json()

                # If some matching batch-meta exists in Solr
                if response_json['response']['numFound']:
                    batch_meta_doc = response_json['response']['docs'][0]

                    # If this exact batch version exists in Solr, skip it
                    if batch_meta_doc['batch-timestamp'] == batch_timestamp:
                        print('Skipping batch {} - already loaded in Solr'.format(batch_id))
                    # If a different version of this batch exists
                    else:
                        # If we're updating, do it
                        if replace:
                            query_text = 'batch-type:{} AND batch-name:{}'.format(batch_type, batch_name)
                            batch_text = "'{} {}'".format(batch_type, batch_name)
                            delete_batch(query_text, solr_url, batch_text)
                            index_batch(batch_dir, solr_url)
                            changes_staged = True
                        # If we're not, throw an error
                        else:
                            sys.exit("Error: Another version of batch '{} {}' already exists in Solr. Add --replace to replace it.".format(batch_type, batch_name))

                # If no matching batch-meta exists in Solr
                else:
                    # Make sure that there are no documents belonging to this batch in Solr
                    url = select_url + '?q=batch-type:{} AND batch-name:{}&rows=0'.format(batch_type, batch_name)
                    print("Checking for the absence of any batch '{} {}' documents in Solr".format(batch_type, batch_name))
                    response = solr_request('GET', url, auth=AUTH)

                    if response.json()['response']['numFound']:
                        sys.exit("Error: Documents with batch-type '{}' and batch-name '{}' exist in Solr, but there is no batch-meta document signifying the existence of the batch. Delete the existing documents before loading this batch.".format(batch_type, batch_name))

                    # If we're updating, throw an error
                    if replace:
                        sys.exit("Error: Batch '{} {}' does not exist in Solr. Remove --replace to index it.".format(batch_type, batch_name))
                    # Else, index the batch
                    else:
                        index_batch(batch_dir, solr_url)
                        changes_staged = True

        # If there are new files to index, index them
        if file_paths:
            for path in file_paths:
                index_file(path, solr_url)
                changes_staged = True

    except Exception as e:
        if not hasattr(e, 'changes_staged'):
            e.changes_staged = changes_staged
        raise

    return changes_staged

def delete(solr_url, batch_type_name=None, batch_ids=None, doc_keys=None):
    """Delete documents or batches.

    Args:
        solr_url (str): The URL to the Solr core to update.
        batch_type_name (tuple[str]): Delete the batch with the given
            type and name. The tuple should have two elements: the
            batch type followed by the batch name.
        batch_ids (list[str]): Delete the batches with these IDs.
        doc_keys (list[str]): Delete the documents with these keys.

    Returns:
        bool: True if any changes were staged in Solr.
    """
    changes_staged = False

    try:
        if batch_type_name:
            batch_type, batch_name = batch_type_name
            query_text = 'batch-type:{} AND batch-name:{}'.format(batch_type, batch_name)
            batch_text = "'{} {}'".format(batch_type, batch_name)
            delete_batch(query_text, solr_url, batch_text)
            changes_staged = True

        # If there is a del_batch_id, use it to delete the old batch
        if batch_ids:
            for batch_id in batch_ids:
                query_text = '{}:{}'.format(BATCH_ID_FIELD, batch_id)
                delete_batch(query_text, solr_url, batch_id)
                changes_staged = True

        # If there is a del_key, use it to delete documents
        if doc_keys:
            for key in doc_keys:
                print('Deleting document with key ' + key)
                data = '<delete><query>{}:{}</query></delete>'.format(UNIQUE_KEY_FIELD, key)
                solr_request('POST', solr_url + '/update', data=data, auth=AUTH, headers={'content-type':'application/xml'})
                changes_staged = True

    except Exception as e:
        if not hasattr(e, 'changes_staged'):
            e.changes_staged = changes_staged
        raise

    return changes_staged

def rollback(solr_url):
    """Roll back changes staged in Solr.

    Args:
        solr_url (str): The URL to the Solr core.
    """
    print('Rolling back changes')

    try:
        solr_request('POST', solr_url + '/update', data='<rollback/>', auth=AUTH, headers={'content-type':'application/xml'})
        print('Rollback successful')

    except Exception as e:
        print('Error: Unable to roll back changes', file=sys.stderr)
        raise

# Validate a batch
# This involves making sure that certain fields are identical in all documents in the batch
def validate_batch(batch_dir):
    """Validate a batch.

    This involves making sure that certain fields are identical in all
    documents in the batch.

    Args:
        batch_dir (str): The path to the batch.
    """
    print('Validating batch')

    # Read batch.json
    batch_json_path = batch_dir + '/batch.json'

    with open(batch_json_path) as batch_json_file:
        batch_json = json.load(batch_json_file)[0]

    # Get all file objects in the directory
    dir_files = [obj for obj in os.scandir(batch_dir) if obj.is_file()]
    # Define the fields that should be identical in all files
    batch_meta_fields = ['batch-type', 'batch-name', 'batch-id', 'batch-timestamp']

    # Validate each data file
    for file_obj in dir_files:
        if file_obj.name.endswith('.json') and file_obj.name != 'batch.json':
            with open(file_obj) as f:
                docs = json.load(f)
                # The fields that didn't match, if any
                mismatched_fields = []

                # Validate each document
                for doc in docs:
                    for field in batch_meta_fields:
                        if doc[field] != batch_json[field]:
                            mismatched_fields.append(field)

                    # If any fields didn't match, error out
                    if mismatched_fields:
                        error_str = "Document '{}' in file '{}' contains batch meta fields that don't match batch.json:\n".format(doc['id'], file_obj.name)
                        str_list = []

                        for field in mismatched_fields:
                            str_list.append('  "{0}": "{1}" (data file) != "{0}": "{2}" (batch.json)'.format(field, doc[field], batch_json[field]))

                        raise ValueError(error_str + '\n'.join(str_list))

    print('Batch is valid')

def index_file(path_like, solr_url):
    """Index a file.

    Args:
        path_like (path-like): The path to the file.
        solr_url (str): The URL to the Solr core.
    """
    with open(path_like) as f:
        print('Indexing file ' + f.name)
        data = f.read()
        solr_request('POST', solr_url + '/update', data=data, auth=AUTH, headers={'content-type':'application/json'})

def index_batch(batch_dir, solr_url):
    """Index a batch.

    Args:
        batch_dir (str): The path to the batch.
        solr_url (str): The URL to the Solr core.
    """
    changes_staged = False

    try:
        # Index all data files
        for obj in os.scandir(batch_dir):
            if obj.is_file():
                if obj.name == 'batch.json':
                    batch_json_file = obj
                elif obj.name.endswith('.json'):
                    index_file(obj, solr_url)
                    changes_staged = True

        # Finally, index batch.json
        index_file(batch_json_file, solr_url)
        changes_staged = True

    except Exception as e:
        e.changes_staged = changes_staged
        raise

def delete_batch(query_text, solr_url, batch_text):
    """Delete a batch.

    Args:
        query_text (str): The Solr query that will be used to find the
            matching batch.
        solr_url (str): The URL to the Solr core.
        batch_text (str): The text that will be printed to refer to the
            batch.
    """
    url = solr_url + '/update'
    changes_staged = False

    try:
        # First, delete the batch-meta document
        print('Deleting batch-meta document for batch ' + batch_text)
        data = '<delete><query>{} AND document-type:batch-meta</query></delete>'.format(query_text)
        solr_request('POST', url, data=data, auth=AUTH, headers={'content-type':'application/xml'})
        changes_staged = True

        # Then delete the data documents
        print('Deleting batch ' + batch_text)
        data = '<delete><query>{}</query></delete>'.format(query_text)
        solr_request('POST', url, data=data, auth=AUTH, headers={'content-type':'application/xml'})

    except Exception as e:
        e.changes_staged = changes_staged
        raise

# Make a request to Solr, print its response, and raise an error if necessary
def solr_request(method, url, data=None, auth=None, headers=None):
    """Make a request to Solr.

    This is a wrapper to requests.request. All params are passed to it.
    Returns the request object.
    """
    if data:
        data = data.encode('utf-8')

    request = requests.request(method, url, data=data, auth=auth, headers=headers)

    try:
        request.raise_for_status()
        print('Solr response:')
        print(request.text)
    except requests.exceptions.HTTPError:
        print('Solr response:', file=sys.stderr)
        print(request.text, file=sys.stderr)
        raise

    return request

if __name__ == '__main__':
    # Get arguments
    kwargs = vars(parse_args())

    # Pop required args
    func = kwargs.pop('func')
    solr_url = kwargs.pop('solr_url')

    # Run the function
    run(func, solr_url, **kwargs)
